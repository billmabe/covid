---
title: "Cleaning the NY Times COVID-19 Case Count Data"
author: "Bill Mabe"
date: "April 10, 2020"
output: html_document
---

```{r setup, include=TRUE}
knitr::opts_chunk$set(echo = TRUE)
```

# PURPOSE

The purpose of this script is to produce two working data frames:
1. US state
2. US city / county

# PROCESS
(a) read in data
(b) find and remove duplicate observations
(c) test each of the files for whether their values for Confirmed, Deaths, and Recovered are cumulative totls or daily totals.
(d) correct revised cumulative case totals
(e) create unbroken time series
(f) fill time series "up" so that all rows have the correct values
(g) create the daily count variables


## A. READ COVID-19 CASE AND DEATH DATA

```{r, messages = FALSE, echo = FALSE, include = FALSE}
require(readr)
require(dplyr)
require(tidyr)
require(lubridate)
require(parsedate)
require(rlang)
require(here)
require(stringr)
require(purrr)
require(rvest)
require(leaflet)

county_dat <- read_csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv")
state_dat <- read_csv("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv")
tests <- read_csv("https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/testing/covid-testing-latest-data-source-details.csv")
```

## B. FIND AND REMOVE DUPLICATE RECORDS (IF THERE ARE ANY)

```{r}
nrow(county_dat %>% distinct()) == nrow(county_dat)
nrow(county_dat %>% distinct(date, county, state)) == nrow(county_dat)

nrow(state_dat %>% distinct()) == nrow(state_dat)
nrow(state_dat %>% distinct(date, state)) == nrow(state_dat)
```

## C. ASCERTAIN WHETHER COUNTS ARE CUMULATIVE OR DAILY

Before doing anything with these data it is first necessary to determine whether the data contains cumulative totals or daily counts.

How do we determine if the counts of cases and deaths are cumulative or by date? If the value of Confirmed today is always greater than the value of Confirmed yesterday, then we can assume that the counts are cumulative.

#### 1. County Data

```{r}
county_distinct_cumul <- county_dat %>% 
  group_by(state, county) %>%
  mutate(lag_cases = lag(cases),
         lag_deaths = lag(deaths),
         cases_is_cumulative = ifelse(cases >= lag_cases, 1, 0),
         dth_is_cumulative = ifelse(deaths >= lag_deaths, 1, 0)
         )

table(county_distinct_cumul$cases_is_cumulative)
table(county_distinct_cumul$dth_is_cumulative)
```

#### 2. State Data

```{r}
state_distinct_cumul <- state_dat %>% 
  group_by(state) %>%
  mutate(lag_cases = lag(cases),
         lag_deaths = lag(deaths),
         cases_is_cumulative = ifelse(cases >= lag_cases, 1, 0),
         dth_is_cumulative = ifelse(deaths >= lag_deaths, 1, 0)
         )
table(state_distinct_cumul$cases_is_cumulative)
table(state_distinct_cumul$dth_is_cumulative)
```

The tables show that in both data sets, the cases and deaths variables are cumulative counts. In a very small number of cases, however, the number of cases at time t is LESS than the number of cases at time t - 1. This suggests that perhaps the local area revised the case or death counts since the original report. To accommodate this and to avoid ending up with daily case values below zero, I use the lead function to change the values of cases and deaths, when the future values of those variables (in the next two days only) were LESS than the current values of those variables. This is intended to improve the accuracy of the daily counts and to backwards revise the cumulative counts so that they reflect changes that local health authorities made to revise the case and death counts. Of course, this assumes that more recent data are more accurate than the original reports. This assumption could be wrong. I think this is, however, a reasonable assumption that also has the benefit of generating negative numbers of COVID-19 cases for some days.

## D. CLEAN THE ORIGINAL CUMULATIVE COUNT VARIABLES

#### 1. County Data

```{r}
county_distinct_rev <- county_distinct_cumul %>% 
  arrange(state, county, date) %>%
  group_by(state, county) %>%
  mutate(lead_cases = lead(cases),
         lead_deaths = lead(deaths),
         lead2_cases = lead(cases, 2),
         lead2_deaths = lead(deaths, 2),
         cases = ifelse(!is.na(lead_cases) & cases > lead_cases, lead_cases, cases),
         deaths = ifelse(!is.na(lead_deaths) & deaths > lead_deaths, lead_deaths, deaths),
         cases = ifelse(!is.na(lead2_cases) & cases > lead2_cases, lead2_cases, cases),
         deaths = ifelse(!is.na(lead2_deaths) & deaths > lead2_deaths, lead2_deaths, deaths)
         )
```

#### 2. State Data

```{r}
state_distinct_rev <- state_distinct_cumul %>% 
  arrange(state, date) %>%
  group_by(state) %>%
  mutate(lead_cases = lead(cases),
         lead_deaths = lead(deaths),
         lead2_cases = lead(cases, 2),
         lead2_deaths = lead(deaths, 2),
         cases = ifelse(!is.na(lead_cases) & cases > lead_cases, lead_cases, cases),
         deaths = ifelse(!is.na(lead_deaths) & deaths > lead_deaths, lead_deaths, deaths),
         cases = ifelse(!is.na(lead2_cases) & cases > lead2_cases, lead2_cases, cases),
         deaths = ifelse(!is.na(lead2_deaths) & deaths > lead2_deaths, lead2_deaths, deaths)
         )
```

## E. CREATE UNBROKEN TIME SERIES FOR EACH GEOGRAPHICAL UNIT

#### Complete the time series using `tidyr::complete`

```{r}
county_complete <- county_distinct_rev %>% 
  complete(nesting(state, county), date = seq(min(date), max(date), by = "day"))

state_complete <- state_distinct_rev %>% 
  complete(nesting(state), date = seq(min(date), max(date), by = "day"))
```

#### See if there are any gaps left in the time series

```{r}
gaps1 <- county_complete %>% 
            group_by(state, county) %>% 
            mutate(no_gap = date - lag(date))
table(gaps1$no_gap)

gaps2 <- state_complete %>% 
            group_by(state) %>% 
            mutate(no_gap = date - lag(date))
table(gaps2$no_gap)
```

If they all equal 1 means there are no gaps in the time series.


## F. FILL THE TIME SERIES UP -- there are no gaps so this code is not necessary.

Convert the NAs to the last value of the variable using fill down, which fills correctly, despite the name. I want to fill in the last recorded value in time before the NA values. I do not want to back fill the most recent value into the past where there are currently NAs.

```{r}
#county_complete_filled <- county_complete %>% group_by(state, county) %>% fill(lag_cases:lead2_deaths, .direction = "down")
#state_complete_filled <- state_complete %>% group_by(state) %>% fill(lag_cases:lead2_deaths, .direction = "down")

#all.equal(county_complete_filled, county_complete)
#all.equal(state_complete_filled, state_complete)
```

## G. CREATE THE DAILY COUNT VARIABLES

#### 1. County File

```{r}
county_data <- county_complete %>% 
                filter(!is.na(county)) %>%
                rename(cumulative_cases = cases,
                       cumulative_deaths = deaths) %>%
                arrange(state, county, date) %>%
                group_by(state, county) %>%
                mutate(cases = cumulative_cases - lag(cumulative_cases),
                       deaths = cumulative_deaths - lag(cumulative_deaths))
```

#### 2. State File

```{r}
state_data <- state_complete %>% 
                filter(!is.na(state)) %>%
                rename(cumulative_cases = cases,
                       cumulative_deaths = deaths) %>%
                arrange(state, date) %>%
                group_by(state) %>%
                mutate(cases = cumulative_cases - lag(cumulative_cases),
                       deaths = cumulative_deaths - lag(cumulative_deaths))
```

# TESTING DATA

```{r}
l <- str_split(tests$Entity, " - ")
tests <- tests %>% mutate(Country = map_chr(l, function(x) x[1]),
                          `Test Units` = map_chr(l, function(x) x[2]),
                          `Log Tests per 1,000` = log(`Cumulative total per thousand`)
                          ) %>%
                   arrange(Country, desc(`Cumulative total`)) %>%
                   group_by(Country) %>%
                   slice(1:1)
  
test_output <- tests %>% 
  arrange(desc(`Cumulative total per thousand`)) %>% 
  select(Country, `Test Units`, Date, `Cumulative total per thousand`, `Cumulative total`, `Log Tests per 1,000`)
nrow(test_output)
```

# LATITUDE / LONGITUDE DATA

```{r}
countries_url <- "https://developers.google.com/public-data/docs/canonical/countries_csv"
ctries <- read_html(countries_url)

# Read data from table
ctry_table <- html_nodes(ctries, "table td") %>%
  html_text()

# Create tibble
country_df <- as_tibble(matrix(ctry_table, ncol = 4, byrow = TRUE), .name_repair = "universal")

# Pull column names from Google
nms <- html_nodes(ctries, "table") %>%
       html_text()
names(country_df) <- str_trim(str_split(nms, "\n")[[1]][1:4])

# Convert lat / lon from char to numeric
country_df <- country_df %>% mutate(latitude = as.numeric(latitude),
                                    longitude = as.numeric(longitude)
                                    )
# country_df
```

# Join Testing Data with Lat Lon Data

```{r}
test_loc <- inner_join(test_output, country_df, by = c("Country" = "name"))
anti_join(test_output, country_df, by = c("Country" = "name"))
# Myanmar has a different name across the two data sets and is therefore dropped in the join. Will fix later.

# nrow(test_loc)
# nrow(test_output)
```

# Draw Map of Cumulative Tests

```{r}
qpal2 <- colorQuantile("Reds", test_loc$`Log Tests per 1,000`, 5)


  map = leaflet(test_loc) %>% addTiles() %>%
    addLegend(values = ~`Cumulative total per thousand`, pal = qpal2, title="Total COVID-19 Tests to Date") %>%
    addProviderTiles(providers$Stamen.Toner) %>%

#   add circle markers last, so they are on top of the polygons:
    addCircleMarkers(data = test_loc, 
                     weight = 10, 
                     color = ~qpal2(`Log Tests per 1,000`), 
                     radius = ~`Log Tests per 1,000`, 
                     opacity = 1, 
                     fillOpacity = 1, 
                     ~longitude, 
                     ~latitude, 
                    labelOptions = labelOptions(
                      offset = c(-100,-140),
                      textOnly = T,
                      style=list(
                        'background'='rgba(255,255,255,0.95)',
                        'border-color' = 'rgba(0,0,0,1)',
                        'border-radius' = '4px',
                        'border-style' = 'solid',
                        'border-width' = '4px'))) %>%
    setView(lng = -73.93, lat = 40.79, zoom = 1)
  map


```

# Write csv files to save

```{r, echo = FALSE, include = FALSE}
write.csv(county_data, file = here("county_data.csv"), row.names = FALSE)
write.csv(state_data, file = here("state_data.csv"), row.names = FALSE)
write.csv(test_loc, file = here("test_output.csv"), row.names = FALSE)
```

```{r deploy}
require(devtools)

if (!require("htmltools"))
  install.packages("htmltools")
require(htmltools)

#devtools::install_github("rstudio/rsconnect")
require(rsconnect)

rsconnect::setAccountInfo(name='practicaldatalab',
			  token='3C7505F0863F43351B605EBDEA791D0F',
			  secret='v0VflFTDtN17aZNlpK8/r9DWDiL8aVqOz2GmO1P/')
deployApp("~/Documents/GitHub/covid/", account = 'practicaldatalab')
```

